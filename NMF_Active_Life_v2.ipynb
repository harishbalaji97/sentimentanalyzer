{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f5d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 2] No such\n",
      "[nltk_data]     file or directory>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##BASIC PREPROCESS RELATED LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "##NLP LIBRARIES - NLTK USED IN BUILDING NLP PIPE LINE\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import urllib.request as url\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import requests\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d200d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TEXT CLEANING\n",
    "##SCRUB WORD FUNCTION REMOVES HTML MARK UPS,SPECIAL CHARACTERS,NON ASCIII CHARACTERS,NON BREAKING SPACES ETC\n",
    "def scrub_words(outtext):\n",
    "    # Replace \\xao characters in text -\n",
    "    # \\xa0 is actually non-breaking space in Latin1 (ISO 8859-1), also chr(160).  \n",
    "    outtext = str(outtext)\n",
    "    outtext = re.sub('\\xa0', ' ', outtext)\n",
    "    outtext = re.sub(\"(\\\\W|\\\\d)\", ' ', outtext) # Replace non ascii and digits\n",
    "    outtext = re.sub('\\n(\\w*?)[\\s]', '', outtext)    # Replace new line characters and following text untill space\n",
    "    outtext = re.sub(\"<.*?>\", ' ', outtext)    # Remove html markup\n",
    "    outtext = re.sub(r'\\\\xa0',' ',outtext)    #outtext = re.sub('\\n',' ',outtext)\n",
    "    outtext = re.sub(r'\\\\n',' ',outtext)    #outtext = re.sub(r'\\xa0',' ',outtext)\n",
    "    outtext = re.sub(r'_',' ',outtext)\n",
    "    outtext = re.sub(r'  ',' ',outtext)\n",
    "    outtext = re.sub('[^a-zA-z\\s]','',outtext)\n",
    "    outtext = re.sub(' +', ' ',outtext)\n",
    "    \" \".join(outtext.strip())\n",
    "    return outtext\n",
    "  \n",
    "def remove_accented_chars(text):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    text = unicodedata.normalize('NFKD', text).encode(\n",
    "        'ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def text_cleaning(scrapped_raw_text):   \n",
    "    cleaned_text = scrub_words(scrapped_raw_text)\n",
    "    return cleaned_text\n",
    "  \n",
    "def text_processing(text):     \n",
    "    stop_words = stopwords.words('english')\n",
    "    tokens = [token for token in word_tokenize(text) if not token in stop_words]\n",
    "    tokens = [token for token in word_tokenize(text) if len(token)>2]\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    ##LEMMATIZING WORDS\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
    "    tokens = [token for token in word_tokenize(text) if len(token)>2]\n",
    "    text = ' '.join(tokens)\n",
    "    return text   \n",
    "\n",
    "def Topic_Modeling(Test):\n",
    "    #Data Collection\n",
    "    df = pd.read_csv(\"Train_V1_yelp\")\n",
    "    #Test=pd.read_csv(\"Yelp_Test.csv\")\n",
    "    df[\"Industry\"].unique(),df[\"Categories_1\"].unique()\n",
    "    df = df.loc[df[\"Industry\"]==\"Active Life\"]\n",
    "    df= df.loc[df[\"Categories_1\"]!=\"Shopping\"]\n",
    "    df['Text'] = df['Text'].apply(str)\n",
    "    df[\"label\"] = df[\"stars\"].apply(lambda x : \"Negative\" if 1<=x<=2 else (\"Neutral\" if x==3 else \"Positive\") )\n",
    "    y = LabelEncoder().fit_transform(df['label'])\n",
    "\n",
    "    #Remove Stop words \n",
    "    stop_words = stopwords.words('english')\n",
    "    df['clean_text'] = df['Text'].apply(text_cleaning)\n",
    "    df['clean_text'] = df['clean_text'].apply(text_processing)\n",
    "    #Train data\n",
    "    X_train=df.reset_index().copy()\n",
    "    X_train.drop(columns=['Unnamed: 0','index'],inplace=True)\n",
    "    X_train.reset_index(inplace=True)\n",
    "    X_train.rename(columns={'index':'Id'},inplace=True)\n",
    "\n",
    "    #Modeling\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words, max_df=0.9, max_features=1000, lowercase=False, ngram_range=(1,3))\n",
    "    tfidf_vectors = vectorizer.fit_transform(X_train.clean_text)\n",
    "    clf = decomposition.NMF(n_components=5, random_state=111,init=None,max_iter=10)\n",
    "    W1 = clf.fit_transform(tfidf_vectors)\n",
    "    H1 = clf.components_\n",
    "\n",
    "    #Topic Extraction\n",
    "    num_words=40\n",
    "    vocab = np.array(vectorizer.get_feature_names())\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in H1])\n",
    "    topics = [' '.join(t) for t in topic_words]\n",
    "\n",
    "    #Dominant topic for data\n",
    "    colnames = [\"Topic\" + str(i) for i in range(clf.n_components)]\n",
    "    docnames = [str(i) for i in range(len(X_train.clean_text))]\n",
    "    df_doc_topic = pd.DataFrame(np.round(W1, 2), columns=colnames, index=docnames)\n",
    "    significant_topic = np.argmax(df_doc_topic.values, axis=1)\n",
    "    df_doc_topic['dominant_topic'] = significant_topic\n",
    "\n",
    "    #Mapping dominant topic,Topics names to main data frame\n",
    "    Tags=pd.read_excel(\"Tags.xlsx\")\n",
    "    Topics_Tags=pd.DataFrame.from_dict({'Id':Tags['Id'],'Topics':Tags['Topics'],'Tags':Tags['Tags']})\n",
    "    doc_topic_train=pd.DataFrame.from_dict({'dominant_topic':df_doc_topic['dominant_topic']})\n",
    "    Train_Tag=pd.merge(left=doc_topic_train,right=Topics_Tags,left_on='dominant_topic',right_on='Id',how='left')\n",
    "    Train_Tag.reset_index(level=0, inplace=True)\n",
    "    Train_Tag.rename(columns={'index':'Tag_Id'},inplace=True)\n",
    "    Train_Tag=Train_Tag[['Tag_Id','Topics', 'Tags']]\n",
    "    Train_Data=pd.merge(left=X_train,right=Train_Tag,left_on='Id',right_on='Tag_Id',how='left')\n",
    "    Train_Data.drop(columns=['Tag_Id'],inplace=True)\n",
    "\n",
    "    #Testing Data\n",
    "    # Test modeling\n",
    "    WHold = clf.transform(vectorizer.transform(Test.Text))\n",
    "    #dominant topic\n",
    "    colnames = [\"Topic\" + str(i) for i in range(clf.n_components)]\n",
    "    docnames = [str(i) for i in range(len(Test.Text))]\n",
    "    df_doc_topic_test = pd.DataFrame(np.round(WHold, 2), columns=colnames, index=docnames)\n",
    "    significant_topic = np.argmax(df_doc_topic_test.values, axis=1)\n",
    "    df_doc_topic_test['dominant_topic'] = significant_topic\n",
    "    #Mapping\n",
    "    doc_topic=pd.DataFrame.from_dict({'dominant_topic':df_doc_topic_test['dominant_topic']})\n",
    "    Final_Tag=pd.merge(left=doc_topic,right=Topics_Tags,left_on='dominant_topic',right_on='Id',how='left')\n",
    "    Final_Tag.reset_index(level=0, inplace=True)\n",
    "    Final_Tag.rename(columns={'index':'Tag_Id'},inplace=True)\n",
    "    Final_Tag_v1=Final_Tag[['Tag_Id','Topics', 'Tags']]\n",
    "    #Final Data Frame\n",
    "    Modeling_Data=pd.merge(left=Test,right=Final_Tag_v1,left_on='Id',right_on='Tag_Id',how='left')\n",
    "    Modeling_Data=Modeling_Data.drop(columns=['Tag_Id'])\n",
    "    return Modeling_Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeed8699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test=Topic_Modeling(pd.read_csv(\"fgk.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4e8f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sender_Email_Type</th>\n",
       "      <th>Receiver_Email_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotions1</th>\n",
       "      <th>date_mod</th>\n",
       "      <th>Topics_x</th>\n",
       "      <th>Tags_x</th>\n",
       "      <th>Departments</th>\n",
       "      <th>emotion_updated</th>\n",
       "      <th>Topics_y</th>\n",
       "      <th>Tags_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Although I've never played this course, I give...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>{'Happy': 0.12, 'Angry': 0.0, 'Surprise': 0.0,...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>02/17/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.12, 'Angry': 0.0, 'Surprise': 0.0,...</td>\n",
       "      <td>course golf play The played courses greens hol...</td>\n",
       "      <td>Golf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Easily the worse course I have played in Phoen...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.0, 'Angry': 0.0, 'Surprise': 0.1, ...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>02/17/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.21, 'Angry': 0.0, 'Surprise': 0.1,...</td>\n",
       "      <td>course golf play The played courses greens hol...</td>\n",
       "      <td>Golf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Played here on a Friday afternoon. The people ...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.06, 'Angry': 0.06, 'Surprise': 0.2...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>02/14/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.28, 'Angry': 0.06, 'Surprise': 0.2...</td>\n",
       "      <td>course golf play The played courses greens hol...</td>\n",
       "      <td>Golf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Golf course is my favorite in the east valley....</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>{'Happy': 0.09, 'Angry': 0.0, 'Surprise': 0.27...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>02/19/22</td>\n",
       "      <td>deal kate symes kate symes pdx price subject c...</td>\n",
       "      <td>Feedback and reviews</td>\n",
       "      <td>Operations</td>\n",
       "      <td>{'Happy': 0.09, 'Angry': 0.0, 'Surprise': 0.27...</td>\n",
       "      <td>course golf play The played courses greens hol...</td>\n",
       "      <td>Golf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Golf</td>\n",
       "      <td>I went out last saturday and had an good exper...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.25, 'Angry': 0.0, 'Surprise': 0.0,...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>02/13/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.64, 'Angry': 0.0, 'Surprise': 0.0,...</td>\n",
       "      <td>gym The equipment machines like Fitness work l...</td>\n",
       "      <td>Gyms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>I LOVE Metta yoga. I moved here about a year a...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.31, 'Angry': 0.0, 'Surprise': 0.31...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>02/08/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.31, 'Angry': 0.0, 'Surprise': 0.31...</td>\n",
       "      <td>yoga studio class classes Yoga instructors Bik...</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>Huge fan of Bikram yoga! It's a 90 minute, tor...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.09, 'Angry': 0.0, 'Surprise': 0.26...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>02/13/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.4, 'Angry': 0.0, 'Surprise': 0.26,...</td>\n",
       "      <td>bike service would back shop said time get cus...</td>\n",
       "      <td>Sporting Goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>At the suggestion of some biker friends, I too...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.21, 'Angry': 0.0, 'Surprise': 0.42...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>02/19/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.35, 'Angry': 0.0, 'Surprise': 0.42...</td>\n",
       "      <td>yoga studio class classes Yoga instructors Bik...</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>Because of my buisness I am lucky enough to tr...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.56, 'Angry': 0.06, 'Surprise': 0.1...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>02/21/22</td>\n",
       "      <td>tablet amazon kid buy apps kindle old work yea...</td>\n",
       "      <td>Purchase, promotion &amp; announcements</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>{'Happy': 0.56, 'Angry': 0.06, 'Surprise': 0.1...</td>\n",
       "      <td>yoga studio class classes Yoga instructors Bik...</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>laxmi.saoji@gmail.com</td>\n",
       "      <td>ygayathri95@yahoo.com</td>\n",
       "      <td>2022-03-10</td>\n",
       "      <td>Yoga</td>\n",
       "      <td>Sumits KILLS!!!\\n\\n\\n...but in a good way, hot...</td>\n",
       "      <td>gmail</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>{'Happy': 0.13, 'Angry': 0.02, 'Surprise': 0.2...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>02/11/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Happy': 0.32, 'Angry': 0.02, 'Surprise': 0.2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  index   Id                   From                     To  \\\n",
       "0            0      0    1  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "1            1      1    2  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "2            2      2    3  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "3            3      3    4  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "4            4      4    5  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "..         ...    ...  ...                    ...                    ...   \n",
       "95          95     95   96  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "96          96     96   97  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "97          97     97   98  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "98          98     98   99  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "99          99     99  100  laxmi.saoji@gmail.com  ygayathri95@yahoo.com   \n",
       "\n",
       "          Date Subject                                               Text  \\\n",
       "0   2022-03-10    Golf  Although I've never played this course, I give...   \n",
       "1   2022-03-10    Golf  Easily the worse course I have played in Phoen...   \n",
       "2   2022-03-10    Golf  Played here on a Friday afternoon. The people ...   \n",
       "3   2022-03-10    Golf  Golf course is my favorite in the east valley....   \n",
       "4   2022-03-10    Golf  I went out last saturday and had an good exper...   \n",
       "..         ...     ...                                                ...   \n",
       "95  2022-03-10    Yoga  I LOVE Metta yoga. I moved here about a year a...   \n",
       "96  2022-03-10    Yoga  Huge fan of Bikram yoga! It's a 90 minute, tor...   \n",
       "97  2022-03-10    Yoga  At the suggestion of some biker friends, I too...   \n",
       "98  2022-03-10    Yoga  Because of my buisness I am lucky enough to tr...   \n",
       "99  2022-03-10    Yoga  Sumits KILLS!!!\\n\\n\\n...but in a good way, hot...   \n",
       "\n",
       "   Sender_Email_Type Receiver_Email_Type  ...     Label  \\\n",
       "0              gmail               Yahoo  ...  Negative   \n",
       "1              gmail               Yahoo  ...  Positive   \n",
       "2              gmail               Yahoo  ...  Positive   \n",
       "3              gmail               Yahoo  ...  Negative   \n",
       "4              gmail               Yahoo  ...  Positive   \n",
       "..               ...                 ...  ...       ...   \n",
       "95             gmail               Yahoo  ...  Positive   \n",
       "96             gmail               Yahoo  ...  Positive   \n",
       "97             gmail               Yahoo  ...  Positive   \n",
       "98             gmail               Yahoo  ...  Positive   \n",
       "99             gmail               Yahoo  ...  Positive   \n",
       "\n",
       "                                              emotion emotions1  date_mod  \\\n",
       "0   {'Happy': 0.12, 'Angry': 0.0, 'Surprise': 0.0,...      Fear  02/17/22   \n",
       "1   {'Happy': 0.0, 'Angry': 0.0, 'Surprise': 0.1, ...       Sad  02/17/22   \n",
       "2   {'Happy': 0.06, 'Angry': 0.06, 'Surprise': 0.2...     Happy  02/14/22   \n",
       "3   {'Happy': 0.09, 'Angry': 0.0, 'Surprise': 0.27...      Fear  02/19/22   \n",
       "4   {'Happy': 0.25, 'Angry': 0.0, 'Surprise': 0.0,...     Happy  02/13/22   \n",
       "..                                                ...       ...       ...   \n",
       "95  {'Happy': 0.31, 'Angry': 0.0, 'Surprise': 0.31...     Happy  02/08/22   \n",
       "96  {'Happy': 0.09, 'Angry': 0.0, 'Surprise': 0.26...     Happy  02/13/22   \n",
       "97  {'Happy': 0.21, 'Angry': 0.0, 'Surprise': 0.42...  Surprise  02/19/22   \n",
       "98  {'Happy': 0.56, 'Angry': 0.06, 'Surprise': 0.1...     Happy  02/21/22   \n",
       "99  {'Happy': 0.13, 'Angry': 0.02, 'Surprise': 0.2...     Happy  02/11/22   \n",
       "\n",
       "                                             Topics_x  \\\n",
       "0   tablet amazon kid buy apps kindle old work yea...   \n",
       "1   tablet amazon kid buy apps kindle old work yea...   \n",
       "2   tablet amazon kid buy apps kindle old work yea...   \n",
       "3   deal kate symes kate symes pdx price subject c...   \n",
       "4   tablet amazon kid buy apps kindle old work yea...   \n",
       "..                                                ...   \n",
       "95  tablet amazon kid buy apps kindle old work yea...   \n",
       "96  tablet amazon kid buy apps kindle old work yea...   \n",
       "97  tablet amazon kid buy apps kindle old work yea...   \n",
       "98  tablet amazon kid buy apps kindle old work yea...   \n",
       "99                                                NaN   \n",
       "\n",
       "                                 Tags_x  Departments  \\\n",
       "0   Purchase, promotion & announcements  Procurement   \n",
       "1   Purchase, promotion & announcements  Procurement   \n",
       "2   Purchase, promotion & announcements  Procurement   \n",
       "3                  Feedback and reviews   Operations   \n",
       "4   Purchase, promotion & announcements  Procurement   \n",
       "..                                  ...          ...   \n",
       "95  Purchase, promotion & announcements  Procurement   \n",
       "96  Purchase, promotion & announcements  Procurement   \n",
       "97  Purchase, promotion & announcements  Procurement   \n",
       "98  Purchase, promotion & announcements  Procurement   \n",
       "99                                  NaN          NaN   \n",
       "\n",
       "                                      emotion_updated  \\\n",
       "0   {'Happy': 0.12, 'Angry': 0.0, 'Surprise': 0.0,...   \n",
       "1   {'Happy': 0.21, 'Angry': 0.0, 'Surprise': 0.1,...   \n",
       "2   {'Happy': 0.28, 'Angry': 0.06, 'Surprise': 0.2...   \n",
       "3   {'Happy': 0.09, 'Angry': 0.0, 'Surprise': 0.27...   \n",
       "4   {'Happy': 0.64, 'Angry': 0.0, 'Surprise': 0.0,...   \n",
       "..                                                ...   \n",
       "95  {'Happy': 0.31, 'Angry': 0.0, 'Surprise': 0.31...   \n",
       "96  {'Happy': 0.4, 'Angry': 0.0, 'Surprise': 0.26,...   \n",
       "97  {'Happy': 0.35, 'Angry': 0.0, 'Surprise': 0.42...   \n",
       "98  {'Happy': 0.56, 'Angry': 0.06, 'Surprise': 0.1...   \n",
       "99  {'Happy': 0.32, 'Angry': 0.02, 'Surprise': 0.2...   \n",
       "\n",
       "                                             Topics_y          Tags_y  \n",
       "0   course golf play The played courses greens hol...            Golf  \n",
       "1   course golf play The played courses greens hol...            Golf  \n",
       "2   course golf play The played courses greens hol...            Golf  \n",
       "3   course golf play The played courses greens hol...            Golf  \n",
       "4   gym The equipment machines like Fitness work l...            Gyms  \n",
       "..                                                ...             ...  \n",
       "95  yoga studio class classes Yoga instructors Bik...            Yoga  \n",
       "96  bike service would back shop said time get cus...  Sporting Goods  \n",
       "97  yoga studio class classes Yoga instructors Bik...            Yoga  \n",
       "98  yoga studio class classes Yoga instructors Bik...            Yoga  \n",
       "99                                                NaN             NaN  \n",
       "\n",
       "[100 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32425d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
